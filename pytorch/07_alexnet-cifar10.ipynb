{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model-zoo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hk4wNbNytnB"
      },
      "source": [
        "# AlexNet CIFAR-10 Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFpHDxd6HHLy"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEpof2LG7NA3"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXz_dHMTHHL0"
      },
      "source": [
        "### Settings and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zWGjESt2QYa",
        "outputId": "9979590a-3ade-4fd6-94cd-41ac455cbad5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = 1\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 10\n",
        "batch_size = 256\n",
        "num_classes = 10\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.Resize((70, 70)),\n",
        "                                       transforms.RandomCrop((64, 64)),\n",
        "                                       transforms.ToTensor()])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize((70, 70)),\n",
        "                                      transforms.CenterCrop((64, 64)),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='data',\n",
        "                                     train=True,\n",
        "                                     transform=train_transforms,\n",
        "                                     download=True)\n",
        "\n",
        "valid_dataset = datasets.CIFAR10(root='data',\n",
        "                                     train=True,\n",
        "                                     transform=test_transforms)\n",
        "    \n",
        "test_dataset = datasets.CIFAR10(root='data',\n",
        "                                    train=False,\n",
        "                                    transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                  batch_size=batch_size)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=False)\n",
        "\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset,\n",
        "                                  batch_size=batch_size)\n",
        "\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
            "Image label dimensions: torch.Size([256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1a6OD4-HHL3"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzsa5IdlOvaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a36e139-0735-4529-8e67-b123e04fc9c0"
      },
      "source": [
        "print('Training Set:\\n')\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.size())\n",
        "    print('Image label dimensions:', labels.size())\n",
        "    print(labels[:10])\n",
        "    break\n",
        "    \n",
        "# Checking the dataset\n",
        "print('\\nValidation Set:')\n",
        "for images, labels in valid_loader:  \n",
        "    print('Image batch dimensions:', images.size())\n",
        "    print('Image label dimensions:', labels.size())\n",
        "    print(labels[:10])\n",
        "    break\n",
        "\n",
        "# Checking the dataset\n",
        "print('\\nTesting Set:')\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.size())\n",
        "    print('Image label dimensions:', labels.size())\n",
        "    print(labels[:10])\n",
        "    break\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set:\n",
            "\n",
            "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
            "Image label dimensions: torch.Size([256])\n",
            "tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3])\n",
            "\n",
            "Validation Set:\n",
            "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
            "Image label dimensions: torch.Size([256])\n",
            "tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3])\n",
            "\n",
            "Testing Set:\n",
            "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
            "Image label dimensions: torch.Size([256])\n",
            "tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PPnruRVXvOP"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), 256 * 6 * 6)\n",
        "        logits = self.classifier(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DFC5GqiuZar"
      },
      "source": [
        "model = AlexNet(num_classes)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdvdfPfBHHL5"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV763NVoZEHY",
        "outputId": "565471c6-37df-4e51-fe74-21671b5bf5ba"
      },
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "        features = features.to(device)\n",
        "        targets = targets.to(device)\n",
        "        logits = model(features)\n",
        "        _, predicted_labels = torch.max(logits, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "    \n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "        features = features.to(device)\n",
        "        targets = targets.to(device)\n",
        "            \n",
        "        # FORWARD AND BACK PROP\n",
        "        logits = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        \n",
        "        # UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        # LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
        "                   %(epoch+1, num_epochs, batch_idx, \n",
        "                     len(train_loader), cost))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
        "              epoch+1, num_epochs, \n",
        "              compute_accuracy(model, train_loader, device=device)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/010 | Batch 0000/0196 | Cost: 2.3023\n",
            "Epoch: 001/010 | Batch 0050/0196 | Cost: 2.0324\n",
            "Epoch: 001/010 | Batch 0100/0196 | Cost: 1.8179\n",
            "Epoch: 001/010 | Batch 0150/0196 | Cost: 1.7826\n",
            "Epoch: 001/010 | Train: 34.622%\n",
            "Epoch: 002/010 | Batch 0000/0196 | Cost: 1.6233\n",
            "Epoch: 002/010 | Batch 0050/0196 | Cost: 1.5748\n",
            "Epoch: 002/010 | Batch 0100/0196 | Cost: 1.5274\n",
            "Epoch: 002/010 | Batch 0150/0196 | Cost: 1.4832\n",
            "Epoch: 002/010 | Train: 44.014%\n",
            "Epoch: 003/010 | Batch 0000/0196 | Cost: 1.4199\n",
            "Epoch: 003/010 | Batch 0050/0196 | Cost: 1.3739\n",
            "Epoch: 003/010 | Batch 0100/0196 | Cost: 1.2270\n",
            "Epoch: 003/010 | Batch 0150/0196 | Cost: 1.3154\n",
            "Epoch: 003/010 | Train: 51.762%\n",
            "Epoch: 004/010 | Batch 0000/0196 | Cost: 1.3643\n",
            "Epoch: 004/010 | Batch 0050/0196 | Cost: 1.2231\n",
            "Epoch: 004/010 | Batch 0100/0196 | Cost: 1.1155\n",
            "Epoch: 004/010 | Batch 0150/0196 | Cost: 1.1914\n",
            "Epoch: 004/010 | Train: 57.084%\n",
            "Epoch: 005/010 | Batch 0000/0196 | Cost: 1.1503\n",
            "Epoch: 005/010 | Batch 0050/0196 | Cost: 1.1258\n",
            "Epoch: 005/010 | Batch 0100/0196 | Cost: 1.0781\n",
            "Epoch: 005/010 | Batch 0150/0196 | Cost: 1.0524\n",
            "Epoch: 005/010 | Train: 59.268%\n",
            "Epoch: 006/010 | Batch 0000/0196 | Cost: 1.0546\n",
            "Epoch: 006/010 | Batch 0050/0196 | Cost: 1.0786\n",
            "Epoch: 006/010 | Batch 0100/0196 | Cost: 1.0087\n",
            "Epoch: 006/010 | Batch 0150/0196 | Cost: 1.0718\n",
            "Epoch: 006/010 | Train: 64.246%\n",
            "Epoch: 007/010 | Batch 0000/0196 | Cost: 0.9216\n",
            "Epoch: 007/010 | Batch 0050/0196 | Cost: 1.0389\n",
            "Epoch: 007/010 | Batch 0100/0196 | Cost: 0.9799\n",
            "Epoch: 007/010 | Batch 0150/0196 | Cost: 1.0145\n",
            "Epoch: 007/010 | Train: 65.572%\n",
            "Epoch: 008/010 | Batch 0000/0196 | Cost: 0.8786\n",
            "Epoch: 008/010 | Batch 0050/0196 | Cost: 0.8990\n",
            "Epoch: 008/010 | Batch 0100/0196 | Cost: 0.8903\n",
            "Epoch: 008/010 | Batch 0150/0196 | Cost: 0.8801\n",
            "Epoch: 008/010 | Train: 66.880%\n",
            "Epoch: 009/010 | Batch 0000/0196 | Cost: 0.8468\n",
            "Epoch: 009/010 | Batch 0050/0196 | Cost: 0.9316\n",
            "Epoch: 009/010 | Batch 0100/0196 | Cost: 0.8741\n",
            "Epoch: 009/010 | Batch 0150/0196 | Cost: 0.8644\n",
            "Epoch: 009/010 | Train: 69.564%\n",
            "Epoch: 010/010 | Batch 0000/0196 | Cost: 0.8130\n",
            "Epoch: 010/010 | Batch 0050/0196 | Cost: 0.8658\n",
            "Epoch: 010/010 | Batch 0100/0196 | Cost: 0.8058\n",
            "Epoch: 010/010 | Batch 0150/0196 | Cost: 0.7485\n",
            "Epoch: 010/010 | Train: 72.538%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sQBgaPtHHL7"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNMFuB1TZhAo",
        "outputId": "515c2095-a740-48bc-bee5-d5e3b4c7cdc2"
      },
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    \n",
        "    train_acc = compute_accuracy(model=model,\n",
        "                                 data_loader=test_loader,\n",
        "                                 device=device)\n",
        "    \n",
        "    test_acc = compute_accuracy(model=model,\n",
        "                                data_loader=test_loader,\n",
        "                                device=device)\n",
        "    \n",
        "    valid_acc = compute_accuracy(model=model,\n",
        "                                 data_loader=valid_loader,\n",
        "                                 device=device)\n",
        "    \n",
        "\n",
        "print(f'Train ACC: {valid_acc:.2f}%')\n",
        "print(f'Validation ACC: {valid_acc:.2f}%')\n",
        "print(f'Test ACC: {test_acc:.2f}%')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train ACC: 73.68%\n",
            "Validation ACC: 73.68%\n",
            "Test ACC: 68.27%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}